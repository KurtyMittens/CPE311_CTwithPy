{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Collecting weather data from an API"
      ],
      "metadata": {
        "id": "y_noMg_wOI4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About the data"
      ],
      "metadata": {
        "id": "GbX2uCMaq6l8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will be collecting daily weather data from the National Centers for Environmental Information (NCEI) API. We will use the Global Historical Climatology\n",
        "Network - Daily (GHCND) data set; see the documentation here."
      ],
      "metadata": {
        "id": "ql5Lp3xkq_Aj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The NCEI is part of the National Oceanic and Atmospheric Administration (NOAA) and, as you can see from the URL for the API, this resource was created when the\n",
        "NCEI was called the NCDC. Should the URL for this resource change in the future, you can search for the NCEI weather API to find the updated one"
      ],
      "metadata": {
        "id": "aZQuENnarCO5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Using the NCEI API**"
      ],
      "metadata": {
        "id": "WmLrje1grDyT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paste your token below."
      ],
      "metadata": {
        "id": "WouK_T28rO4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def make_request(endpoint, payload= None):\n",
        "  \"\"\"\n",
        "  This function allows us to connect to the API using the python built in\n",
        "  request module.\n",
        "\n",
        "  *endpoints - are the locations/parts of the api you want to go\n",
        "               to or continue to.\n",
        "  *header - tokens are put in here\n",
        "  *payload/param - are the Pagination of the certain part of the API\n",
        "  \"\"\"\n",
        "  return requests.get(\n",
        "      f'https://www.ncei.noaa.gov/cdo-web/api/v2/{endpoint}',\n",
        "      headers = {\n",
        "          'token':'anPgrgSWrWgUYFXULhgBXbwIMcbuJWps'\n",
        "          # Token Given by the ncei.noaa.gov/\n",
        "      },\n",
        "      params=payload)"
      ],
      "metadata": {
        "id": "sjkDVw92OMXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collect All Data Points for 2018 In NYC (Various Stations)"
      ],
      "metadata": {
        "id": "BtR3Cui5tUaB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can make a loop to query for all the data points one day at a time. Here we create a list of all the results"
      ],
      "metadata": {
        "id": "olNJ1h2eu36m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "from IPython import display # constant displaying statuses: less space in terminal\n",
        "\n",
        "current = datetime.date(2018, 1, 1) # Starting date, variable for iteration\n",
        "end = datetime.date(2019, 1, 1) # End of the date\n",
        "\n",
        "# array for the data gathered in the whole 2018\n",
        "results = []\n",
        "\n",
        "while current < end: # loops until current >= end\n",
        "  display.clear_output(wait=True)\n",
        "  display .display(f'Gathering Data for {str(current)}')\n",
        "\n",
        "  response = make_request(\n",
        "      'data',\n",
        "      {\n",
        "          'datasetid' : 'GHCND',\n",
        "          'locationid': 'CITY:US360019', # NYC City ID\n",
        "          'startdate': current, # Gets all the data in a particular\n",
        "          'enddate': current,   # day only\n",
        "          'units':'metric',\n",
        "          'limit':1000\n",
        "      }\n",
        "  )\n",
        "\n",
        "  if response.ok: # validate if the response is ok\n",
        "  # appends all the gathered items to existing results array\n",
        "    results.extend(response.json()['results'])\n",
        "\n",
        "  # timedelta() calculates the difference of the date to the param you input\n",
        "  # params = days=0, seconds=0, microseconds=0,\n",
        "  # milliseconds=0, minutes=0, hours=0, weeks=0\n",
        "  current += datetime.timedelta(days=1)\n"
      ],
      "metadata": {
        "id": "0stezP18u3Xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can create a dataframe with all this data. Notice there are multiple stations with values for each datatype on a given day. We don't know what the stations are, but we\n",
        "can look them up and add them to the data"
      ],
      "metadata": {
        "id": "cbXNjLHfy7qR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(results) # array to Data Frame\n",
        "df.head()"
      ],
      "metadata": {
        "id": "TI6eAg_yzBCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save this data to a file:"
      ],
      "metadata": {
        "id": "MYSFs_kf0nFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the dataframe to csv excluding the indexes\n",
        "df.to_csv(\"/content/nyc_weather_2018.csv\", index=False)"
      ],
      "metadata": {
        "id": "5mtm8Sgc1qak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And write it to the database"
      ],
      "metadata": {
        "id": "l4OyDLUc089_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "\"\"\"\n",
        "practical ways to set your sqlite db.\n",
        "\"\"\"\n",
        "with sqlite3.connect('/content/weather.db') as connection:\n",
        "  df.to_sql(\n",
        "    'weather', connection, index=False, if_exists='replace'\n",
        "  ) # dataframe to sql!"
      ],
      "metadata": {
        "id": "a41p8GgC1qzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For learning about merging dataframes, we will also get the data mapping station IDs to information about the station:"
      ],
      "metadata": {
        "id": "ZZSFffj21CU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = make_request(\n",
        "    'stations',\n",
        "    {\n",
        "        'datasetid': 'GHCND',\n",
        "        'locationid': 'CITY:US360019',\n",
        "        'limit':1000\n",
        "    }\n",
        ")\n",
        "\n",
        "stations = pd.DataFrame(response.json()['results'])[['id', 'name','latitude','longitude', 'elevation']]\n",
        "\n",
        "stations.to_csv('/content/weather_stations.db', index=False)\n",
        "\n",
        "with sqlite3.connect('/content/weather.db') as connection:\n",
        "  stations.to_sql(\n",
        "      'stations', connection, index=False, if_exists='replace'\n",
        "  )"
      ],
      "metadata": {
        "id": "LclXmFBm1rYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# END"
      ],
      "metadata": {
        "id": "S6MsT5ZmABRT"
      }
    }
  ]
}